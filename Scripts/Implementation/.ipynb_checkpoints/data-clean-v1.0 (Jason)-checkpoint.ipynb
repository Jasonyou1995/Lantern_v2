{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import packages and read from ./data repo\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "corpus_root = 'data/drug_data'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "ids = wordlists.fileids()\n",
    "\n",
    "# use three documents as samples\n",
    "corp = {}\n",
    "for x in range(0,10):\n",
    "    corp[\"d{0}\".format(x)]=wordlists.words(ids[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corp[\"d0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords Corpus\n",
      "\n",
      "This corpus contains lists of stop words for several languages.  These\n",
      "are high-frequency grammatical words which are usually ignored in text\n",
      "retrieval applications.\n",
      "\n",
      "They were obtained from:\n",
      "http://anoncvs.postgresql.org/cvsweb.cgi/pgsql/src/backend/snowball/stopwords/\n",
      "\n",
      "The English list has been augmented\n",
      "https://github.com/nltk/nltk_data/issues/22\n",
      "\n",
      "The German list has been corrected\n",
      "https://github.com/nltk/nltk_data/pull/49\n",
      "\n",
      "A Kazakh list has been added\n",
      "https://github.com/nltk/nltk_data/pull/52\n",
      "\n",
      "\n",
      "(1059, 1135, 994)\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.readme())\n",
    "\n",
    "# Get the frequency distribution for each document\n",
    "fd = {}\n",
    "for x in range(0,10):\n",
    "    fd[\"fd{0}\".format(x)]=nltk.FreqDist(corp[\"d{0}\".format(x)])\n",
    "\n",
    "# the words that only shown once\n",
    "print(\n",
    "    len(fd['fd1'].hapaxes()),\n",
    "    len(fd['fd2'].hapaxes()),\n",
    "    len(fd['fd3'].hapaxes()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'.', 1312), (u',', 986), (u'(', 545), (u'of', 381), (u'and', 344), (u'the', 307), (u'sexual', 285), (u'1', 250), (u'\\u2013', 231), (u')', 228)]\n",
      "[(u'.', 912), (u',', 736), (u'and', 382), (u'of', 358), (u'(', 352), (u'the', 291), (u'harassment', 211), (u'sexual', 194), (u')', 186), (u'a', 153)]\n",
      "[(u'.', 1150), (u',', 561), (u'and', 323), (u'of', 313), (u'(', 292), (u'the', 279), (u'-', 146), (u').', 135), (u'in', 133), (u'to', 131)]\n"
     ]
    }
   ],
   "source": [
    "# most common words before cleaning\n",
    "print(fd['fd1'].most_common(10))\n",
    "print(fd['fd2'].most_common(10))\n",
    "print(fd['fd3'].most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_stopwords = set(['the', 'a', '.', 'studies', 'students', 'schools', 'prevalence', 'national', 'general', 'whether', 'statistically', 'probabilities', 'covered', 'subject', 'associated', 'indicate', 'testing', 'research'])  # we can define our own stop words in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0xb1 in position 22: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-81e1c5a87193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fd{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-81e1c5a87193>\u001b[0m in \u001b[0;36mfeature_extractor\u001b[0;34m(words, freq, min_len, min_freq, my_stop)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     return(set([(w.lower(), freq.get(w))\n\u001b[0;32m----> 8\u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/util.pyc\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34m'block reader %s() should return list or tuple.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/plaintext.pyc\u001b[0m in \u001b[0;36m_read_word_block\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Read 20 lines at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mstartpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytebuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mnew_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;31m# If we're at a '\\r', then read one extra character, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;31m# Decode the bytes into unicode characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incr_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# If we got bytes but couldn't decode any, then read further.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_incr_decode\u001b[0;34m(self, bytes)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                 \u001b[0;31m# If the exception occurs at the end of the string,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aarya/anaconda/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xb1 in position 22: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Returns a set of word-frequency pairs chosen based on given limitations\n",
    "# param@words: list of words from input documents\n",
    "# param@freq: frequency distributions for each word from words\n",
    "# param@min_len: the minimum length of a word to be chosen\n",
    "# param@min_freq: the minimum times a word appear in the doc\n",
    "def feature_extractor(words, freq, min_len, min_freq, my_stop=set()):\n",
    "    return(set([(w.lower(), freq.get(w))\n",
    "           for w in set(words)\n",
    "           if len(w) >= min_len\n",
    "           and freq.get(w) >= min_freq\n",
    "           and w not in stopwords.words(fileids='english')\n",
    "           and w not in my_stopwords]))\n",
    "    # I want to add a filter to check whether the 'w' is a English word (with Lexical data)\n",
    "\n",
    "def print_size(feature, id):\n",
    "    print(' '.join(['Choosen', str(len(feature)), 'words from document', str(id)]))\n",
    "\n",
    "# The numerical parameters in here can be tuned\n",
    "f = {}\n",
    "for x in range(0,10):\n",
    "    f[\"f{0}\".format(x)]=feature_extractor(corp['d{0}'.format(x)], fd['fd{0}'.format(x)], 7, 7, my_stopwords)\n",
    "\n",
    "print_size(f['f1'], 1)\n",
    "print_size(f['f2'], 2)\n",
    "print_size(f['f3'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosen 311 words from document \"union features\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(u'harassment', 1198),\n",
       " (u'victimization', 633),\n",
       " (u'bullying', 470),\n",
       " (u'research', 263),\n",
       " (u'violence', 223),\n",
       " (u'journal', 222),\n",
       " (u'reported', 181),\n",
       " (u'bullied', 172),\n",
       " (u'climate', 165),\n",
       " (u'adolescents', 141),\n",
       " (u'american', 130),\n",
       " (u'ethnicity', 125),\n",
       " (u'orientation', 122),\n",
       " (u'harassed', 113),\n",
       " (u'experience', 111),\n",
       " (u'sexually', 106),\n",
       " (u'behavior', 106),\n",
       " (u'lesbian', 100),\n",
       " (u'distressing', 98),\n",
       " (u'experiences', 94),\n",
       " (u'bisexual', 93),\n",
       " (u'females', 92),\n",
       " (u'student', 92),\n",
       " (u'relationships', 90),\n",
       " (u'significant', 88),\n",
       " (u'perpetration', 87),\n",
       " (u'factors', 85),\n",
       " (u'university', 81),\n",
       " (u'adolescent', 77),\n",
       " (u'support', 76),\n",
       " (u'differences', 76),\n",
       " (u'psychology', 74),\n",
       " (u'heterosexual', 72),\n",
       " (u'identity', 70),\n",
       " (u'different', 67),\n",
       " (u'physical', 67),\n",
       " (u'response', 66),\n",
       " (u'experienced', 65),\n",
       " (u'attitudes', 64),\n",
       " (u'transgender', 64),\n",
       " (u'outcomes', 61),\n",
       " (u'significantly', 60),\n",
       " (u'internet', 60),\n",
       " (u'context', 60),\n",
       " (u'espelage', 59),\n",
       " (u'mitchell', 58),\n",
       " (u'distress', 58),\n",
       " (u'fineran', 57),\n",
       " (u'children', 56),\n",
       " (u'relationship', 55),\n",
       " (u'behaviors', 55),\n",
       " (u'exposure', 54),\n",
       " (u'coercive', 53),\n",
       " (u'aggression', 51),\n",
       " (u'respondents', 49),\n",
       " (u'characteristics', 48),\n",
       " (u'findings', 47),\n",
       " (u'related', 46),\n",
       " (u'masculinity', 46),\n",
       " (u'regression', 46),\n",
       " (u'minority', 45),\n",
       " (u'victims', 43),\n",
       " (u'african', 43),\n",
       " (u'analysis', 43),\n",
       " (u'included', 42),\n",
       " (u'education', 40),\n",
       " (u'individual', 39),\n",
       " (u'compared', 38),\n",
       " (u'increased', 37),\n",
       " (u'teacher', 36),\n",
       " (u'teachers', 35),\n",
       " (u'greater', 34),\n",
       " (u'predictors', 34),\n",
       " (u'results', 33),\n",
       " (u'coercion', 33),\n",
       " (u'diversity', 33),\n",
       " (u'academic', 33),\n",
       " (u'adolescence', 32),\n",
       " (u'options', 32),\n",
       " (u'students', 32),\n",
       " (u'variance', 31),\n",
       " (u'questions', 30),\n",
       " (u'participants', 30),\n",
       " (u'neglect', 30),\n",
       " (u'variables', 30),\n",
       " (u'someone', 30),\n",
       " (u'example', 29),\n",
       " (u'sociosexuality', 28),\n",
       " (u'taiwanese', 28),\n",
       " (u'retrieved', 28),\n",
       " (u'opposite', 28),\n",
       " (u'friends', 28),\n",
       " (u'components', 28),\n",
       " (u'classical', 27),\n",
       " (u'including', 27),\n",
       " (u'effects', 27),\n",
       " (u'perceived', 27),\n",
       " (u'coerced', 27),\n",
       " (u'unrestricted', 26),\n",
       " (u'participation', 26),\n",
       " (u'romantic', 26),\n",
       " (u'partner', 26),\n",
       " (u'department', 26),\n",
       " (u'victimized', 25),\n",
       " (u'individuals', 25),\n",
       " (u'harassing', 25),\n",
       " (u'positive', 25),\n",
       " (u'addition', 25),\n",
       " (u'prevention', 25),\n",
       " (u'particularly', 24),\n",
       " (u'percent', 24),\n",
       " (u'community', 24),\n",
       " (u'unwanted', 24),\n",
       " (u'california', 24),\n",
       " (u'perpetrators', 24),\n",
       " (u'psychological', 23),\n",
       " (u'against', 23),\n",
       " (u'semester', 23),\n",
       " (u'protective', 22),\n",
       " (u'literature', 22),\n",
       " (u'predictor', 22),\n",
       " (u'particular', 22),\n",
       " (u'kentucky', 22),\n",
       " (u'depressive', 22),\n",
       " (u'hispanic', 22),\n",
       " (u'conforming', 22),\n",
       " (u'questioning', 22),\n",
       " (u'interpersonal', 21),\n",
       " (u'maltreatment', 21),\n",
       " (u'hegemonic', 21),\n",
       " (u'problems', 21),\n",
       " (u'connectedness', 21),\n",
       " (u'impairment', 21),\n",
       " (u'demographic', 20),\n",
       " (u'overall', 20),\n",
       " (u'symptomatology', 20),\n",
       " (u'comments', 20),\n",
       " (u'straight', 20),\n",
       " (u'attracted', 19),\n",
       " (u'negative', 19),\n",
       " (u'association', 18),\n",
       " (u'classes', 18),\n",
       " (u'kennair', 18),\n",
       " (u'obscene', 18),\n",
       " (u'measured', 18),\n",
       " (u'williams', 18),\n",
       " (u'network', 18),\n",
       " (u'predicted', 17),\n",
       " (u'national', 17),\n",
       " (u'perception', 17),\n",
       " (u'benbenishty', 17),\n",
       " (u'explained', 17),\n",
       " (u'cisgender', 16),\n",
       " (u'identified', 16),\n",
       " (u'connolly', 16),\n",
       " (u'withdrawal', 16),\n",
       " (u'biological', 16),\n",
       " (u'multiple', 16),\n",
       " (u'policies', 16),\n",
       " (u'current', 16),\n",
       " (u'emotional', 16),\n",
       " (u'something', 16),\n",
       " (u'elevated', 16),\n",
       " (u'evolutionary', 15),\n",
       " (u'bendixen', 15),\n",
       " (u'intersection', 15),\n",
       " (u'however', 15),\n",
       " (u'analyses', 15),\n",
       " (u'juvonen', 15),\n",
       " (u'outcome', 15),\n",
       " (u'identities', 15),\n",
       " (u'present', 15),\n",
       " (u'augelli', 14),\n",
       " (u'symptoms', 14),\n",
       " (u'evolution', 14),\n",
       " (u'conditional', 14),\n",
       " (u'psychosocial', 14),\n",
       " (u'critical', 14),\n",
       " (u'reference', 14),\n",
       " (u'interest', 14),\n",
       " (u'differently', 14),\n",
       " (u'appendix', 14),\n",
       " (u'greytak', 14),\n",
       " (u'expression', 14),\n",
       " (u'members', 13),\n",
       " (u'perspective', 13),\n",
       " (u'chinese', 12),\n",
       " (u'disclosed', 12),\n",
       " (u'schmitt', 12),\n",
       " (u'perceptions', 12),\n",
       " (u'satisfaction', 12),\n",
       " (u'americans', 12),\n",
       " (u'engagement', 12),\n",
       " (u'pacific', 12),\n",
       " (u'potential', 12),\n",
       " (u'coefficients', 12),\n",
       " (u'predict', 12),\n",
       " (u'partners', 11),\n",
       " (u'presented', 11),\n",
       " (u'targeted', 11),\n",
       " (u'pediatric', 11),\n",
       " (u'prejudice', 11),\n",
       " (u'symptom', 11),\n",
       " (u'canadian', 11),\n",
       " (u'meaningful', 11),\n",
       " (u'membership', 11),\n",
       " (u'chronic', 11),\n",
       " (u'especially', 11),\n",
       " (u'hasegawa', 10),\n",
       " (u'occasionally', 10),\n",
       " (u'personality', 10),\n",
       " (u'advances', 10),\n",
       " (u'drinking', 10),\n",
       " (u'malamuth', 10),\n",
       " (u'delinquency', 10),\n",
       " (u'experiencing', 10),\n",
       " (u'solution', 10),\n",
       " (u'responses', 10),\n",
       " (u'component', 10),\n",
       " (u'although', 10),\n",
       " (u'suggested', 10),\n",
       " (u'sakaguchi', 10),\n",
       " (u'another', 10),\n",
       " (u'contact', 10),\n",
       " (u'patterns', 10),\n",
       " (u'sociosexual', 10),\n",
       " (u'population', 10),\n",
       " (u'discrimination', 10),\n",
       " (u'verkuyten', 10),\n",
       " (u'subtypes', 10),\n",
       " (u'adverse', 10),\n",
       " (u'disagree', 9),\n",
       " (u'respond', 9),\n",
       " (u'restricted', 9),\n",
       " (u'covariates', 9),\n",
       " (u'checklist', 9),\n",
       " (u'problem', 9),\n",
       " (u'scantron', 9),\n",
       " (u'whereas', 9),\n",
       " (u'homophobic', 9),\n",
       " (u'development', 9),\n",
       " (u'cultural', 9),\n",
       " (u'accounted', 9),\n",
       " (u'behavioral', 9),\n",
       " (u'fitzgerald', 8),\n",
       " (u'revealed', 8),\n",
       " (u'intraparental', 8),\n",
       " (u'attraction', 8),\n",
       " (u'difference', 8),\n",
       " (u'reduced', 8),\n",
       " (u'relative', 8),\n",
       " (u'gilreath', 8),\n",
       " (u'previous', 8),\n",
       " (u'islander', 8),\n",
       " (u'hypothesis', 8),\n",
       " (u'interactions', 8),\n",
       " (u'address', 8),\n",
       " (u'stereotypes', 8),\n",
       " (u'explore', 8),\n",
       " (u'consistent', 8),\n",
       " (u'concerning', 8),\n",
       " (u'culture', 8),\n",
       " (u'evidence', 8),\n",
       " (u'pornography', 8),\n",
       " (u'generally', 8),\n",
       " (u'pettigrew', 8),\n",
       " (u'subjects', 8),\n",
       " (u'attachment', 8),\n",
       " (u'performance', 8),\n",
       " (u'classroom', 8),\n",
       " (u'researchers', 8),\n",
       " (u'intergroup', 8),\n",
       " (u'september', 7),\n",
       " (u'feminist', 7),\n",
       " (u'exclusively', 7),\n",
       " (u'eigenvalue', 7),\n",
       " (u'stronger', 7),\n",
       " (u'gangestad', 7),\n",
       " (u'college', 7),\n",
       " (u'targets', 7),\n",
       " (u'technology', 7),\n",
       " (u'investigate', 7),\n",
       " (u'approach', 7),\n",
       " (u'attention', 7),\n",
       " (u'article', 7),\n",
       " (u'delinquent', 7),\n",
       " (u'comparison', 7),\n",
       " (u'dynamics', 7),\n",
       " (u'columbia', 7),\n",
       " (u'utilized', 7),\n",
       " (u'comprised', 7),\n",
       " (u'utilization', 7),\n",
       " (u'relations', 7),\n",
       " (u'defined', 7),\n",
       " (u'achievement', 7),\n",
       " (u'populations', 7),\n",
       " (u'centered', 7),\n",
       " (u'controlling', 7),\n",
       " (u'interaction', 7),\n",
       " (u'similar', 7),\n",
       " (u'confucian', 7),\n",
       " (u'variable', 7),\n",
       " (u'adversely', 7),\n",
       " (u'services', 7),\n",
       " (u'suggest', 7),\n",
       " (u'simpson', 7),\n",
       " (u'categories', 7),\n",
       " (u'studies', 7),\n",
       " (u'frequently', 7),\n",
       " (u'medical', 7),\n",
       " (u'diverse', 7)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a dictionary of word-frequency pairs from the union of several feature sets\n",
    "def union_choosen_features(setlist):\n",
    "#     if (not all([type(arg) is set for arg in args])):\n",
    "#          raise ValueError('Input must be sets of word-frequency pairs.')\n",
    "#     if (len(args) < 2):\n",
    "#         raise ValueError('At least 2 arguments needed.')\n",
    "    N = len(setlist)  # number of documents\n",
    "    result = dict()  # word:frequency pairs\n",
    "    for i in range(N):\n",
    "        for w in setlist[i]:  # access each feature set\n",
    "            if w[0] in result.keys():\n",
    "                result[w[0]] += w[1]\n",
    "            else:\n",
    "                result[w[0]] = w[1]\n",
    "    return result\n",
    "       \n",
    "union_features = union_choosen_features(f.values())\n",
    "print_size(union_features, '\\\"union features\\\"')\n",
    "sorted(union_features.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integer 0 Integer 1 Integer 2\n"
     ]
    }
   ],
   "source": [
    "# The way to assign a sequence of variables (you can safely ignore this part)\n",
    "for i in range(3):\n",
    "    vars()[''.join(['arg', str(i)])] = ' '.join(['Integer', str(i)])\n",
    "print(arg0, arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/drug_data\n",
      "Choosen 443 words from document \"union features\"\n",
      "data/SH_data\n",
      "Choosen 311 words from document \"union features\"\n",
      "data/bully_data\n",
      "Choosen 274 words from document \"union features\"\n",
      "data/vandalism_data\n",
      "Choosen 340 words from document \"union features\"\n",
      "[(u'vandalism', 684), (u'behavior', 184), (u'student', 182), (u'residence', 166), (u'education', 100), (u'teachers', 97), (u'research', 94), (u'community', 87), (u'journal', 75), (u'discipline', 70), (u'environment', 70), (u'university', 70), (u'project', 70), (u'property', 67), (u'analysis', 66), (u'activity', 60), (u'teacher', 59), (u'content', 56), (u'treatment', 53), (u'illinois', 53), (u'significantly', 52), (u'downloaded', 52), (u'parents', 52), (u'control', 51), (u'actions', 50), (u'programs', 50), (u'college', 48), (u'individual', 46), (u'relationship', 46), (u'process', 46), (u'reported', 44), (u'butterworth', 38), (u'however', 37), (u'evidence', 37), (u'alcohol', 36), (u'results', 35), (u'incidence', 35), (u'punishment', 35), (u'development', 35), (u'children', 34), (u'program', 33), (u'violence', 32), (u'involvement', 32), (u'expulsion', 31), (u'suspension', 31), (u'changes', 31), (u'related', 31), (u'principals', 31), (u'principal', 30), (u'although', 30), (u'objects', 29), (u'schools', 28), (u'respondents', 28), (u'dimension', 28), (u'classroom', 28), (u'effects', 27), (u'selected', 27), (u'district', 27), (u'baseline', 27), (u'hearing', 26), (u'strategies', 26), (u'interaction', 26), (u'american', 26), (u'variable', 26), (u'support', 26), (u'specific', 25), (u'angeles', 25), (u'educational', 25), (u'workshops', 24), (u'officials', 24), (u'strategy', 24), (u'aggression', 24), (u'significant', 24), (u'housing', 24), (u'attitude', 23), (u'secondary', 23), (u'factors', 23), (u'variables', 23), (u'problem', 23), (u'athletes', 23), (u'charged', 23), (u'increase', 22), (u'personal', 22), (u'association', 22), (u'involved', 22), (u'richmond', 22), (u'indicated', 22), (u'authority', 22), (u'greater', 22), (u'national', 21), (u'constitutional', 21), (u'misconduct', 20), (u'freshmen', 20), (u'television', 20), (u'setting', 20), (u'vorobyeva', 20), (u'average', 20), (u'solution', 19), (u'consultation', 19), (u'observations', 19), (u'following', 19), (u'orientation', 19), (u'vandals', 19), (u'destructive', 19), (u'personality', 18), (u'activities', 18), (u'experimental', 18), (u'positive', 18), (u'incidents', 18), (u'authorities', 18), (u'ideological', 17), (u'consequences', 17), (u'propensity', 17), (u'kruzhkova', 17), (u'problems', 17), (u'youngsters', 17), (u'procedures', 16), (u'educators', 16), (u'dissertation', 16), (u'barometer', 16), (u'training', 16), (u'vaughan', 16), (u'assessment', 16), (u'differences', 16), (u'present', 16), (u'abstracts', 16), (u'buildings', 16), (u'readiness', 16), (u'microfilms', 15), (u'perceived', 15), (u'paragraph', 15), (u'decision', 15), (u'communication', 15), (u'motivation', 15), (u'successful', 15), (u'climate', 15), (u'freedom', 15), (u'disciplinary', 15), (u'included', 15), (u'psychology', 15), (u'athletic', 14), (u'radical', 14), (u'conduct', 14), (u'receiving', 14), (u'decrease', 14), (u'motives', 14), (u'genesis', 14), (u'childhood', 14), (u'without', 14), (u'prevention', 14), (u'material', 13), (u'conditions', 13), (u'krivoshchekova', 13), (u'homeroom', 13), (u'officer', 13), (u'security', 13), (u'characteristics', 13), (u'measure', 13), (u'various', 13), (u'generally', 13), (u'members', 13), (u'science', 13), (u'reducing', 13), (u'anxiety', 13), (u'procedural', 13), (u'influence', 13), (u'cluster', 13), (u'offense', 13), (u'provincial', 13), (u'northern', 13), (u'bulletin', 13), (u'orientations', 13), (u'excessive', 12), (u'participate', 12), (u'conservative', 12), (u'parameters', 12), (u'january', 12), (u'goldstein', 12), (u'approach', 12), (u'particular', 12), (u'composite', 12), (u'seniors', 12), (u'discretion', 12), (u'suspend', 12), (u'liberal', 12), (u'teenagers', 12), (u'measures', 12), (u'chickering', 11), (u'primary', 11), (u'arrested', 11), (u'written', 11), (u'international', 11), (u'behaviors', 11), (u'psychological', 11), (u'elementary', 11), (u'several', 11), (u'substantive', 11), (u'building', 11), (u'regression', 11), (u'compared', 11), (u'viewing', 11), (u'responsibility', 11), (u'meetings', 10), (u'nafpaktitis', 10), (u'azaroff', 10), (u'decreased', 10), (u'success', 10), (u'literature', 10), (u'questionnaire', 10), (u'formation', 10), (u'another', 10), (u'indicators', 10), (u'systems', 10), (u'reinforcement', 10), (u'accused', 10), (u'classrooms', 10), (u'contact', 10), (u'goldman', 10), (u'allegedly', 10), (u'important', 10), (u'physical', 10), (u'thought', 10), (u'supreme', 9), (u'methods', 9), (u'gladstone', 9), (u'scientist', 9), (u'consultants', 9), (u'punitive', 9), (u'linwood', 9), (u'obtained', 9), (u'washington', 9), (u'autonomy', 9), (u'curriculum', 9), (u'connection', 9), (u'appears', 9), (u'because', 9), (u'normative', 9), (u'emotional', 9), (u'december', 9), (u'percent', 9), (u'judgment', 9), (u'effective', 9), (u'circuit', 9), (u'september', 8), (u'assigned', 8), (u'solutions', 8), (u'finally', 8), (u'sabatino', 8), (u'aspects', 8), (u'increased', 8), (u'modification', 8), (u'reasonable', 8), (u'including', 8), (u'superintendent', 8), (u'findings', 8), (u'schoolwide', 8), (u'suspended', 8), (u'vandalisma', 8), (u'attitudes', 8), (u'sophomores', 8), (u'teaching', 8), (u'consumption', 8), (u'package', 8), (u'vandalistic', 8), (u'suggests', 8), (u'involving', 8), (u'appropriate', 8), (u'adolescene', 8), (u'statute', 8), (u'employed', 8), (u'administrators', 8), (u'society', 8), (u'consultant', 8), (u'internal', 8), (u'suggest', 8), (u'meeting', 8), (u'failure', 8), (u'difficult', 8), (u'purpose', 8), (u'guardian', 8), (u'response', 8), (u'charges', 8), (u'correlation', 8), (u'colleges', 7), (u'developed', 7), (u'relation', 7), (u'consists', 7), (u'religious', 7), (u'tendency', 7), (u'regarded', 7), (u'sovereignty', 7), (u'situation', 7), (u'effectiveness', 7), (u'psychologist', 7), (u'drinking', 7), (u'constitution', 7), (u'reading', 7), (u'presented', 7), (u'decisionmaking', 7), (u'official', 7), (u'suggested', 7), (u'aggressive', 7), (u'ability', 7), (u'participation', 7), (u'relationships', 7), (u'attended', 7), (u'parental', 7), (u'respectively', 7), (u'finding', 7), (u'regulations', 7), (u'institute', 7), (u'experience', 7), (u'context', 7), (u'grounds', 7), (u'consulting', 7), (u'features', 7), (u'sanction', 7), (u'addition', 7), (u'direction', 7), (u'negative', 7), (u'adopted', 7), (u'materials', 7), (u'delivery', 7), (u'environmental', 7), (u'general', 7), (u'appointed', 7), (u'chicago', 7), (u'policies', 7), (u'vandalize', 7), (u'disobedience', 7), (u'different', 7), (u'whereas', 7), (u'proportions', 7), (u'oriented', 7), (u'motivational', 7), (u'subscales', 7), (u'federal', 7), (u'academic', 7), (u'amendment', 7), (u'intentional', 7)]\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "def main():\n",
    "    #create the dictionary\n",
    "    keys = [\"Drug\", \"Harrass\", \"Bullying\", \"Vandalism\"]\n",
    "    paths = [\"data/drug_data\", \"data/SH_data\", \"data/bully_data\", \"data/vandalism_data\"]\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        z = 0\n",
    "        corpus_root = path\n",
    "        wordlists = PlaintextCorpusReader(corpus_root, '.*\\.txt')\n",
    "        ids = wordlists.fileids()\n",
    "\n",
    "        # collect all the documents from the folder\n",
    "        corp = {}\n",
    "        for x in range(0,10):\n",
    "            corp[\"d{0}\".format(x)]=wordlists.words(ids[x])\n",
    "\n",
    "        fd = {}\n",
    "        for x in range(0,10):\n",
    "            fd[\"fd{0}\".format(x)]=nltk.FreqDist(corp[\"d{0}\".format(x)])\n",
    "        \n",
    "        f = {}\n",
    "        for x in range(0,10):\n",
    "            f[\"f{0}\".format(x)]=feature_extractor(corp[\"d{0}\".format(x)], fd['fd{0}'.format(x)], 7, 7, my_stopwords)\n",
    "        \n",
    "        union_features = union_choosen_features(f.values())\n",
    "        print_size(union_features, '\\\"union features\\\"')\n",
    "        print(keys[z])\n",
    "        all_data[keys[z]] = sorted(union_features.items(), key=lambda x: x[1], reverse=True)\n",
    "        z+=1\n",
    "main()  \n",
    "print(all_data['Drug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drug']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
